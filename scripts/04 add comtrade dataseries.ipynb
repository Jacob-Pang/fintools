{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fintools\n",
    "\n",
    "from pyutils.pytask_scheduler import PyTaskScheduler\n",
    "from pyutils.pytask_scheduler.request_provider import RequestProviderManager\n",
    "from fintools.datareader import get_database\n",
    "from fintools.dataseries.comtrade_dataseries import ComtradeGoodsDataSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_database = get_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_database = get_database(\"macro_database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "comtrade_dataseries = ComtradeGoodsDataSeries(\"comtrade_dataseries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_database.add_connected_child_node(comtrade_dataseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_database.save_database_memory(access_token=access_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>category</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>macro_database_dbase_memory</td>\n",
       "      <td>ARTIFACT</td>\n",
       "      <td>persistent database memory structure</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            ID  category                           description\n",
       "0  macro_database_dbase_memory  ARTIFACT  persistent database memory structure"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_database(\"macro_database\").get_catalog()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Updating Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_provider, update_pytasks = comtrade_dataseries.get_update_pytasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_provider_manager = RequestProviderManager()\n",
    "request_provider_manager.add_request_provider(request_provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1657756109: Running task: pytask_63664_16 ... completed at 1657756113.\n",
      "PyTask scheduler tasks remaining: 202355\n",
      "1657756113: Running task: pytask_87536_16 ... "
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jacob\\OneDrive\\Desktop\\repositories\\fintools\\scripts\\03 add comtrade dataseries.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jacob/OneDrive/Desktop/repositories/fintools/scripts/03%20add%20comtrade%20dataseries.ipynb#ch0000019?line=0'>1</a>\u001b[0m PyTaskScheduler(request_provider_manager)\u001b[39m.\u001b[39;49mrun_tasks(update_pytasks, access_token\u001b[39m=\u001b[39;49maccess_token)\n",
      "File \u001b[1;32mc:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyutils\\pytask_scheduler\\__init__.py:95\u001b[0m, in \u001b[0;36mPyTaskScheduler.run_tasks\u001b[1;34m(self, tasks, reschedule_verbose, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m     api_keys[request_provider_id] \u001b[39m=\u001b[39m request_provider\u001b[39m.\u001b[39mapi_key\n\u001b[0;32m     92\u001b[0m     request_provider\u001b[39m.\u001b[39mrun_requests(task\u001b[39m.\u001b[39mtask_id, task\u001b[39m.\u001b[39mrequest_provider_usage \\\n\u001b[0;32m     93\u001b[0m                 \u001b[39m.\u001b[39mget(request_provider_id))\n\u001b[1;32m---> 95\u001b[0m task(api_keys\u001b[39m=\u001b[39mapi_keys, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m# Run task\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcompleted at \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mint\u001b[39m(time\u001b[39m.\u001b[39mtime())\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     98\u001b[0m \u001b[39mfor\u001b[39;00m request_provider_id, request_provider \u001b[39min\u001b[39;00m request_providers\u001b[39m.\u001b[39mitems():\n",
      "File \u001b[1;32mc:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyutils\\pytask_scheduler\\__init__.py:39\u001b[0m, in \u001b[0;36mPyTask.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtask_count:\n\u001b[0;32m     37\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtask_count \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m---> 39\u001b[0m task_output \u001b[39m=\u001b[39m FunctionWrapper\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     40\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscheduled_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfreq \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfreq \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtask_count \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     41\u001b[0m         \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtask_count \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m) \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocked_count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyutils\\wrappers.py:57\u001b[0m, in \u001b[0;36mFunctionWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39many\u001b[39m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrapped_function(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdated_kwargs(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs))\n",
      "File \u001b[1;32mc:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\fintools\\dataseries\\comtrade_dataseries.py:85\u001b[0m, in \u001b[0;36mComtradeGoodsDataSeries.update_pytask\u001b[1;34m(self, access_token, trade_direction_id, reporter_comtrade_id, counterparty_comtrade_id, reporting_entity, counterparty_entity)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_tracker[permutation_key] \u001b[39m=\u001b[39m year\n\u001b[0;32m     84\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mversion_timestamp \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m: \u001b[39m# Assumed no prior saved data\u001b[39;00m\n\u001b[1;32m---> 85\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave_data(observation_pdf, access_token\u001b[39m=\u001b[39;49maccess_token,\n\u001b[0;32m     86\u001b[0m             partition_columns\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mtrade_direction\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mreporting_entity\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39myear\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m     88\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_data(observation_pdf, access_token\u001b[39m=\u001b[39maccess_token)\n",
      "File \u001b[1;32mc:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyutils\\database\\github_database\\github_dataframe.py:32\u001b[0m, in \u001b[0;36mGitHubParquetDataFrame.save_data\u001b[1;34m(self, artifact_data, authenticated_repo, access_token, partition_columns, *args, **kwargs)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msave_data\u001b[39m(\u001b[39mself\u001b[39m, artifact_data: \u001b[39many\u001b[39m, \u001b[39m*\u001b[39margs, authenticated_repo: Repository \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     31\u001b[0m     access_token: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, partition_columns: \u001b[39mlist\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 32\u001b[0m     \u001b[39mreturn\u001b[39;00m ParquetDataFrame\u001b[39m.\u001b[39msave_data(\u001b[39mself\u001b[39m, artifact_data, \u001b[39m*\u001b[39margs, authenticated_repo\u001b[39m=\u001b[39mauthenticated_repo,\n\u001b[0;32m     33\u001b[0m             access_token\u001b[39m=\u001b[39maccess_token, partition_columns\u001b[39m=\u001b[39mpartition_columns, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyutils\\database\\dataframe.py:117\u001b[0m, in \u001b[0;36mParquetDataFrame.save_data\u001b[1;34m(self, artifact_data, partition_columns, *args, **kwargs)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msave_data\u001b[39m(\u001b[39mself\u001b[39m, artifact_data: pd\u001b[39m.\u001b[39mDataFrame, \u001b[39m*\u001b[39margs, partition_columns: \u001b[39mlist\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    115\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpartition_columns \u001b[39m=\u001b[39m partition_columns\n\u001b[1;32m--> 117\u001b[0m     \u001b[39mreturn\u001b[39;00m DataFrame\u001b[39m.\u001b[39msave_data(\u001b[39mself\u001b[39m, artifact_data, \u001b[39m*\u001b[39margs,\n\u001b[0;32m    118\u001b[0m             partition_cols\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpartition_columns, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyutils\\database\\dataframe.py:20\u001b[0m, in \u001b[0;36mDataFrame.save_data\u001b[1;34m(self, artifact_data, *args, **kwargs)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataframe_schema\u001b[39m.\u001b[39mset_reduced_schema(artifact_data)\n\u001b[0;32m     18\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataframe_schema\u001b[39m.\u001b[39mapply_reduced_schema(artifact_data, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m---> 20\u001b[0m \u001b[39mreturn\u001b[39;00m Artifact\u001b[39m.\u001b[39msave_data(\u001b[39mself\u001b[39m, artifact_data, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyutils\\database\\artifact.py:20\u001b[0m, in \u001b[0;36mArtifact.save_data\u001b[1;34m(self, artifact_data, *args, **kwargs)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdestroy_node(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     19\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_connection_dpath()\n\u001b[1;32m---> 20\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_data_to_path(artifact_data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_node_path(), \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     21\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mversion_timestamp \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "File \u001b[1;32mc:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyutils\\database\\github_database\\github_dataframe.py:55\u001b[0m, in \u001b[0;36mGitHubParquetDataFrame.save_data_to_path\u001b[1;34m(self, artifact_data, path, authenticated_repo, access_token, partition_cols, commit_message, *args, **kwargs)\u001b[0m\n\u001b[0;32m     52\u001b[0m     os\u001b[39m.\u001b[39mmakedirs(from_temp_local_directory_path)\n\u001b[0;32m     54\u001b[0m temp_local_file_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(from_temp_local_directory_path, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_node_id)\n\u001b[1;32m---> 55\u001b[0m ParquetDataFrame\u001b[39m.\u001b[39;49msave_data_to_path(\u001b[39mself\u001b[39;49m, artifact_data, temp_local_file_path,\n\u001b[0;32m     56\u001b[0m         partition_cols\u001b[39m=\u001b[39;49mpartition_cols)\n\u001b[0;32m     58\u001b[0m push_directory(authenticated_repo, from_temp_local_directory_path,\n\u001b[0;32m     59\u001b[0m         os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(path), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_branch(), commit_message)\n\u001b[0;32m     61\u001b[0m shutil\u001b[39m.\u001b[39mrmtree(from_temp_local_directory_path)\n",
      "File \u001b[1;32mc:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyutils\\database\\dataframe.py:122\u001b[0m, in \u001b[0;36mParquetDataFrame.save_data_to_path\u001b[1;34m(self, artifact_data, path, partition_cols, *args, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msave_data_to_path\u001b[39m(\u001b[39mself\u001b[39m, artifact_data: pd\u001b[39m.\u001b[39mDataFrame, path: \u001b[39mstr\u001b[39m,\n\u001b[0;32m    121\u001b[0m     partition_cols: \u001b[39mlist\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 122\u001b[0m     artifact_data\u001b[39m.\u001b[39;49mto_parquet(path, partition_cols\u001b[39m=\u001b[39;49mpartition_cols)\n\u001b[0;32m    124\u001b[0m     \u001b[39m\"\"\" to be evaluated if renaming is required.\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[39m    if not os.path.isdir(path):\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[39m        return\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[39m        os.rename(file_path, os.path.join(dpath, f\"{self.data_node_id}.parquet\"))\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:207\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 207\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:2835\u001b[0m, in \u001b[0;36mDataFrame.to_parquet\u001b[1;34m(self, path, engine, compression, index, partition_cols, storage_options, **kwargs)\u001b[0m\n\u001b[0;32m   2749\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2750\u001b[0m \u001b[39mWrite a DataFrame to the binary parquet format.\u001b[39;00m\n\u001b[0;32m   2751\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2831\u001b[0m \u001b[39m>>> content = f.read()\u001b[39;00m\n\u001b[0;32m   2832\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2833\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mparquet\u001b[39;00m \u001b[39mimport\u001b[39;00m to_parquet\n\u001b[1;32m-> 2835\u001b[0m \u001b[39mreturn\u001b[39;00m to_parquet(\n\u001b[0;32m   2836\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   2837\u001b[0m     path,\n\u001b[0;32m   2838\u001b[0m     engine,\n\u001b[0;32m   2839\u001b[0m     compression\u001b[39m=\u001b[39mcompression,\n\u001b[0;32m   2840\u001b[0m     index\u001b[39m=\u001b[39mindex,\n\u001b[0;32m   2841\u001b[0m     partition_cols\u001b[39m=\u001b[39mpartition_cols,\n\u001b[0;32m   2842\u001b[0m     storage_options\u001b[39m=\u001b[39mstorage_options,\n\u001b[0;32m   2843\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   2844\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parquet.py:416\u001b[0m, in \u001b[0;36mto_parquet\u001b[1;34m(df, path, engine, compression, index, storage_options, partition_cols, **kwargs)\u001b[0m\n\u001b[0;32m    414\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(partition_cols, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    415\u001b[0m     partition_cols \u001b[39m=\u001b[39m [partition_cols]\n\u001b[1;32m--> 416\u001b[0m impl \u001b[39m=\u001b[39m get_engine(engine)\n\u001b[0;32m    418\u001b[0m path_or_buf: FilePath \u001b[39m|\u001b[39m WriteBuffer[\u001b[39mbytes\u001b[39m] \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mBytesIO() \u001b[39mif\u001b[39;00m path \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m path\n\u001b[0;32m    420\u001b[0m impl\u001b[39m.\u001b[39mwrite(\n\u001b[0;32m    421\u001b[0m     df,\n\u001b[0;32m    422\u001b[0m     path_or_buf,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    427\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    428\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parquet.py:52\u001b[0m, in \u001b[0;36mget_engine\u001b[1;34m(engine)\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m     50\u001b[0m             error_msgs \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m - \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(err)\n\u001b[1;32m---> 52\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[0;32m     53\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUnable to find a usable engine; \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     54\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtried using: \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpyarrow\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mfastparquet\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     55\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mA suitable version of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     56\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpyarrow or fastparquet is required for parquet \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     57\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msupport.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     58\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTrying to import the above resulted in these errors:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     59\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00merror_msgs\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     60\u001b[0m     )\n\u001b[0;32m     62\u001b[0m \u001b[39mif\u001b[39;00m engine \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpyarrow\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     63\u001b[0m     \u001b[39mreturn\u001b[39;00m PyArrowImpl()\n",
      "\u001b[1;31mImportError\u001b[0m: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet."
     ]
    }
   ],
   "source": [
    "PyTaskScheduler(request_provider_manager).run_tasks(update_pytasks, access_token=access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "90d99a365a6800d6d3b874802d775db992b69c47481bfc65e12294d647a46c22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
